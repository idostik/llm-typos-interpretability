# Exploration of how do LLMs correct typos (from the view of mechanistic interpretability)
Code for my final project for Blue Dot Impacts AI Alignment course.

I tried to uncover how does typo correction work in LLMs and what are the key components that allow this ability. The jupyter notebook contains all of my code and steps that I took in order to uncover the underlying mechanisms in a rough, unpolished form. I am working on writing a blogpost about it, which I will link here when finished. 

This was my first bigger mechanistic interpretability project, so I am certain that a lot of things could be done better. I have learned a lot from this and will definetely continue learning about mech interp further.